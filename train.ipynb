{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Rimjhim\n",
      "[nltk_data]     Singh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Rimjhim\n",
      "[nltk_data]     Singh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Rimjhim\n",
      "[nltk_data]     Singh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, AdamW\n",
    "import torch\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_excel(\"dataset\\MEDICSUMM.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REPORT</th>\n",
       "      <th>SUMMARY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thyroid Stimulating Hormone (TSH): 2.5 mIU/L (...</td>\n",
       "      <td>TSH: 2.5 mIU/L (Normal) - Normal thyroid stimu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thyroid Stimulating Hormone (TSH): 0.1 mIU/L (...</td>\n",
       "      <td>TSH: 0.1 mIU/L (Low) - Low thyroid stimulating...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hemoglobin (Hb): 13.0 g/dL (Low)\\nRed Blood Ce...</td>\n",
       "      <td>Hemoglobin (Hb): 13.0 g/dL (Low) - Indicates l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sodium (Na): 140 mEq/L (Normal)\\nPotassium (K)...</td>\n",
       "      <td>Sodium: 140 mEq/L (Normal)\\nPotassium: 4.0 mEq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Albumin: 4.5 g/dL (Normal)\\nTotal Protein: 7.0...</td>\n",
       "      <td>Albumin: 4.5 g/dL (Normal)\\nTotal Protein: 7.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Total Cholesterol: 200 mg/dL (Borderline High)...</td>\n",
       "      <td>Total Cholesterol: 200 mg/dL (Borderline High)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Thyroid Stimulating Hormone (TSH): 2.5 mIU/L (...</td>\n",
       "      <td>TSH: 2.5 mIU/L (Normal) - Normal thyroid stimu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Troponin I: 0.02 ng/mL (Normal)\\nCreatine Kina...</td>\n",
       "      <td>Troponin I: 0.02 ng/mL (Normal) - Normal tropo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HIV: Negative\\nSyphilis: Negative\\nChlamydia: ...</td>\n",
       "      <td>HIV: Negative - No evidence of HIV infection.\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Prothrombin Time (PT): 12 seconds (Normal)\\nAc...</td>\n",
       "      <td>PT: 12 seconds (Normal) - Normal prothrombin t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DHEA-Sulfate: 200 mcg/dL (Normal)\\nInterpretat...</td>\n",
       "      <td>DHEA-Sulfate: 200 mcg/dL (Normal) - Normal deh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>C-Reactive Protein (CRP): 0.5 mg/dL (Normal)\\n...</td>\n",
       "      <td>CRP: 0.5 mg/dL (Normal) - Normal C-reactive pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               REPORT  \\\n",
       "0   Thyroid Stimulating Hormone (TSH): 2.5 mIU/L (...   \n",
       "1   Thyroid Stimulating Hormone (TSH): 0.1 mIU/L (...   \n",
       "2   Hemoglobin (Hb): 13.0 g/dL (Low)\\nRed Blood Ce...   \n",
       "3   Sodium (Na): 140 mEq/L (Normal)\\nPotassium (K)...   \n",
       "4   Albumin: 4.5 g/dL (Normal)\\nTotal Protein: 7.0...   \n",
       "5   Total Cholesterol: 200 mg/dL (Borderline High)...   \n",
       "6   Thyroid Stimulating Hormone (TSH): 2.5 mIU/L (...   \n",
       "7   Troponin I: 0.02 ng/mL (Normal)\\nCreatine Kina...   \n",
       "8   HIV: Negative\\nSyphilis: Negative\\nChlamydia: ...   \n",
       "9   Prothrombin Time (PT): 12 seconds (Normal)\\nAc...   \n",
       "10  DHEA-Sulfate: 200 mcg/dL (Normal)\\nInterpretat...   \n",
       "11  C-Reactive Protein (CRP): 0.5 mg/dL (Normal)\\n...   \n",
       "\n",
       "                                              SUMMARY  \n",
       "0   TSH: 2.5 mIU/L (Normal) - Normal thyroid stimu...  \n",
       "1   TSH: 0.1 mIU/L (Low) - Low thyroid stimulating...  \n",
       "2   Hemoglobin (Hb): 13.0 g/dL (Low) - Indicates l...  \n",
       "3   Sodium: 140 mEq/L (Normal)\\nPotassium: 4.0 mEq...  \n",
       "4   Albumin: 4.5 g/dL (Normal)\\nTotal Protein: 7.0...  \n",
       "5   Total Cholesterol: 200 mg/dL (Borderline High)...  \n",
       "6   TSH: 2.5 mIU/L (Normal) - Normal thyroid stimu...  \n",
       "7   Troponin I: 0.02 ng/mL (Normal) - Normal tropo...  \n",
       "8   HIV: Negative - No evidence of HIV infection.\\...  \n",
       "9   PT: 12 seconds (Normal) - Normal prothrombin t...  \n",
       "10  DHEA-Sulfate: 200 mcg/dL (Normal) - Normal deh...  \n",
       "11  CRP: 0.5 mg/dL (Normal) - Normal C-reactive pr...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sg = pd.read_excel(\"dataset/CMS32_DESC_LONG_SHORT_SG.xlsx\")\n",
    "df_dx = pd.read_excel(\"dataset/CMS32_DESC_LONG_SHORT_DX.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "difficult_words_sg = df_sg.set_index('SHORT DESCRIPTION')['LONG DESCRIPTION'].to_dict()\n",
    "difficult_words_dx = df_dx.set_index('SHORT DESCRIPTION')['LONG DESCRIPTION'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Lowercasing\n",
    "    text = text.lower()\n",
    "    # Remove special characters and digits\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
    "    # Join tokens back into text\n",
    "    preprocessed_text = ' '.join(lemmatized_tokens)\n",
    "    return preprocessed_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_difficult_words(text, difficult_words):\n",
    "    for word, explanation in difficult_words.items():\n",
    "        text = text.replace(word, explanation)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_reports(reports):\n",
    "    preprocessed_reports = []\n",
    "    for report in reports:\n",
    "        # Preprocess text\n",
    "        report = preprocess_text(report)\n",
    "        # Replace difficult words with explanations from both datasets\n",
    "        report = replace_difficult_words(report,difficult_words_sg)\n",
    "        report = replace_difficult_words(report, difficult_words_dx)\n",
    "        preprocessed_reports.append(report)\n",
    "    return preprocessed_reports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['processed_report'] = preprocess_reports(dataset['REPORT'])\n",
    "dataset['processed_summary'] = preprocess_reports(dataset['SUMMARY'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(dataset, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41251efeb3554e8b9a41e521b516b1f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rimjhim Singh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:148: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Rimjhim Singh\\.cache\\huggingface\\hub\\models--t5-small. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf93a437757f4275812b760ceb259f67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4937880d83ab4689baf81a8cc407524e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding inputs and outputs\n",
    "train_inputs = tokenizer(train_data['processed_report'].tolist(), padding=True, truncation=True, return_tensors=\"pt\")\n",
    "train_outputs = tokenizer(train_data['processed_summary'].tolist(), padding=True, truncation=True, return_tensors=\"pt\")\n",
    "test_inputs = tokenizer(test_data['processed_report'].tolist(), padding=True, truncation=True, return_tensors=\"pt\")\n",
    "test_outputs = tokenizer(test_data['processed_summary'].tolist(), padding=True, truncation=True, return_tensors=\"pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2aadc8f1827456abbbc0b00d03dc7ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b629f227694461a897fbc97e07989f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f53f2103d9e84e5bae8d0afbcc6bd2ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained('t5-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rimjhim Singh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Model training\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "model.train()\n",
    "for epoch in range(3):  \n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(input_ids=train_inputs['input_ids'], labels=train_outputs['input_ids'])\n",
    "    loss = outputs.loss\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 7102,   208,  2841,     3,     7,    63, 18118,   159,  2841,     3,\n",
      "           524,   521,  2258,    26,    23,     9,  2841,     3,  5307,   127,\n",
      "            52,    88,     9,  2841,  8868,  2841,     3,  2248,   794,     1,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  792, 16462,  5453,    26,    40,  4947,   747,   306,     3,   107,\n",
      "            26,    40, 16462,  5453,    26,    40,  1389,     3,    40,    26,\n",
      "            40, 16462,  5453,    26,    40,   306,     3,    17,  3380,   120,\n",
      "          2110,  1599,  5453,    26,    40,  4947,   747,   306,  8868,  4947,\n",
      "           747,   306,   792, 16462,     3,    17,  3380,   120,  2110,  1599,\n",
      "           306,     3,    40,    26,    40, 16462,     1,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [24731, 14063,    77,     3,   107,   115,     3,   122,    26,    40,\n",
      "           731,  1131,  1717,  2358,  3476,     3,    52,   115,    75,  3293,\n",
      "          6361,    51,   731,  7614,  2358,  2908,     3,   102,    75,   208,\n",
      "           731,  1243, 11736,   302,  4866,  2908,     3,    51,    75,   208,\n",
      "             3,   102,   122,   306,  1243, 11736,   302,  4866, 24731, 14063,\n",
      "            77,     3,    51,   524,     3,   102,   122,  1243, 11736,   302,\n",
      "          4866, 24731, 14063,    77,  6145,     3,    51,   524,    75,     3,\n",
      "           122,    26,    40,   872,  1717,  2358,  3476,     3,   210,   115,\n",
      "            75,     3,   635,  1389,  3829,  1655,  3476,     3,   635,  1389,\n",
      "          8868, 17947,     3,    75,   115,    75,  3130,   757,    46, 11658,\n",
      "         15712,     3,    51,    75,   208,     1],\n",
      "        [26054, 24664, 11932,     3,    17,     7,   107,  1337,    83,   731,\n",
      "           339,     3,   189,    63, 12907,   630,     3,  1725,    26,    40,\n",
      "           306,   792,  6467,    23,    32,    26,    32,   189,    63,    52,\n",
      "           106,   630,     3,  1725,    26,    40,   306,  8868, 17947, 26054,\n",
      "          2952,     1,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [ 3935,  6645,  3619,  5764,   102,  5453,    26,    40,  1389,  8868,\n",
      "          1389,  3935,  6645,  3619,   794,     1,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [ 2306,    77,     3,   122,    26,    40,  1389,   792,  3619,     3,\n",
      "           122,    26,    40,  1389,   792,     3,  3727,    23, 14446,    77,\n",
      "          5453,    26,    40,  1389,   491,  1258,   747,     3, 24613,     9,\n",
      "             7,    15,   491,   102,     3,    83,  1389,    38,  2274,   342,\n",
      "         17925,  7031,  1010,     9,     7,    15,    38,    17,     3,    83,\n",
      "          1389,     3,     9,  1618,   630, 17925,  7031,  1010,     9,     7,\n",
      "            15,  4445,     3,    83,  1389, 15167,  5453,    26,    40,  1389,\n",
      "             3, 19787,  4502,  5453,    26,    40,  1389,  8868,  1389,  2446,\n",
      "           102,     1,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [ 5227,   106,    77,     3,  1725,    51,    40,  1389,  8830,   630,\n",
      "             3,  2917,     9,     7,    15,    51,   115,     3,  2406,    51,\n",
      "           115,     3,    83,  1389,  8868,  1389, 16643,  2392,  3920,   277,\n",
      "             1,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [19049,     3,    29,     9,   140,  1824,    40,  1389, 26110,     3,\n",
      "           157,   140,  1824,    40,  1389, 19782,  1599,     3,    75,    40,\n",
      "           140,  1824,    40,  1389,  2647, 17089,   342,     3,   107,   509,\n",
      "           140,  1824,    40,  1389,  1717,     3,  1462,     9, 23383,  2293,\n",
      "          5453,    26,    40,  1389,  8830,    77,   630,  5453,    26,    40,\n",
      "          1389, 17320,  5453,    26,    40,  1389,  8868,  1389,     3,   115,\n",
      "          1167,     1,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [26054, 24664, 11932,     3,    17,     7,   107,  1337,    83,  1389,\n",
      "           339,     3,   189,    63, 12907,   630,     3,  1725,    26,    40,\n",
      "          1389,   792,  6467,    23,    32,    26,    32,   189,    63,    52,\n",
      "           106,   630,     3,  1725,    26,    40,  1389,  8868,  1389, 26054,\n",
      "          2952,     1,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0]])\n"
     ]
    }
   ],
   "source": [
    "print(train_inputs['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['serum test normal dheasulfate serum test normal dheasulfate serum test normal dheasulfate serum test normal dheasulfate serum test normal dheasulfate serum test normal dheasulfate serum test normal dheasulfate serum test normal dheasulfate serum test normal dheasulfate serum test normal dheasulfate serum test', 'Prothrombin time pt second normal activated partial thromboplastin time aptt second normal international normalized ratio inr normal interpretation normal coagulation panel', 'thyroid stimulating hormone thyroid stimulating hormone tsh miul normal free thyroxine ngdl normal total triiodothyronine ngdl normal interpretation normal thyroid panel']\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Generate outputs\n",
    "    test_outputs_predicted = model.generate(input_ids=test_inputs['input_ids'], max_length=150)\n",
    "    \n",
    "    # Convert test_outputs_predicted to list of token IDs if necessary\n",
    "    if isinstance(test_outputs_predicted, torch.Tensor):\n",
    "        test_outputs_predicted = test_outputs_predicted.tolist()\n",
    "    elif isinstance(test_outputs_predicted[0], torch.Tensor):\n",
    "        test_outputs_predicted = [tensor.tolist() for tensor in test_outputs_predicted]\n",
    "\n",
    "# Decode predictions\n",
    "decoded_predictions = []\n",
    "for token_ids in test_outputs_predicted:\n",
    "    decoded_tokens = tokenizer.decode(token_ids, skip_special_tokens=True)\n",
    "    decoded_predictions.append(decoded_tokens)\n",
    "\n",
    "print(decoded_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(input_text):\n",
    "    # Preprocess the input text\n",
    "    preprocessed_input = preprocess_text(input_text)\n",
    "\n",
    "    # Tokenization\n",
    "    input_tokenized = tokenizer(preprocessed_input, return_tensors=\"pt\")\n",
    "\n",
    "    # Model inference\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(input_tokenized['input_ids'], max_length=50, num_beams=4, early_stopping=True)\n",
    "\n",
    "    # Decode the summary\n",
    "    summary = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEDICAL_DOCUMENT = \"\"\" \n",
    "duplications of the alimentary tract are well - known but rare congenital malformations that can occur anywhere in the gastrointestinal ( gi ) tract from the tongue to the anus . while midgut duplications are the most common , foregut duplications such as oesophagus , stomach , and parts 1 and 2 of the duodenum account for approximately one - third of cases . \n",
    " they are most commonly seen either in the thorax or abdomen or in both as congenital thoracoabdominal duplications . \n",
    " cystic oesophageal duplication ( ced ) , the most common presentation , is often found in the lower third part ( 60 - 95% ) and on the right side [ 2 , 3 ] . hydatid cyst ( hc ) is still an important health problem throughout the world , particularly in latin america , africa , and mediterranean areas . \n",
    " turkey , located in the mediterranean area , shares this problem , with an estimated incidence of 20/100 000 . \n",
    " most commonly reported effected organ is liver , but in children the lungs are the second most frequent site of involvement [ 4 , 5 ] . in both ced and hc , the presentation depends on the site and the size of the cyst . \n",
    " hydatid cysts are far more common than other cystic intrathoracic lesions , especially in endemic areas , so it is a challenge to differentiate ced from hc in these countries . here , \n",
    " we present a 7-year - old girl with intrathoracic cystic mass lesion , who had been treated for hydatid cyst for 9 months , but who turned out to have oesophageal cystic duplication . \n",
    " a 7-year - old girl was referred to our clinic with coincidentally established cystic intrathoracic lesion during the investigation of aetiology of anaemia . \n",
    " the child was first admitted with loss of vision in another hospital ten months previously . \n",
    " the patient 's complaints had been attributed to pseudotumour cerebri due to severe iron deficiency anaemia ( haemoglobin : 3 g / dl ) . \n",
    " chest radiography and computed tomography ( ct ) images resulted in a diagnosis of cystic intrathoracic lesion ( fig . \n",
    " the cystic mass was accepted as a type 1 hydatid cyst according to world health organization ( who ) classification . \n",
    " after 9 months of medication , no regression was detected in ct images , so the patient was referred to our department . \n",
    " an ondirect haemagglutination test result was again negative . during surgery , after left thoracotomy incision , a semi - mobile cystic lesion , which was almost seven centimetres in diameter , with smooth contour , was found above the diaphragm , below the lung , outside the pleura ( fig . \n",
    " the entire fluid in the cyst was aspirated ; it was brown and bloody ( fig . \n",
    " 2 ) . the diagnosis of cystic oesophageal duplication was considered , and so an attachment point was searched for . \n",
    " it was below the hiatus , on the lower third left side of the oesophagus , and it also was excised completely through the hiatus . \n",
    " pathologic analysis of the specimen showed oesophageal mucosa with an underlying proper smooth muscle layer . \n",
    " computed tomography image of the cystic intrathoracic lesion cystic lesion with brownish fluid in the cyst \n",
    " compressible organs facilitate the growth of the cyst , and this has been proposed as a reason for the apparent prevalence of lung involvement in children . diagnosis is often incidental and can be made with serological tests and imaging [ 5 , 7 ] . \n",
    " laboratory investigations include the casoni and weinberg skin tests , indirect haemagglutination test , elisa , and the presence of eosinophilia , but can be falsely negative because children may have a poor serological response to eg . \n",
    " false - positive reactions are related to the antigenic commonality among cestodes and conversely seronegativity can not exclude hydatidosis . \n",
    " false - negative results are observed when cysts are calcified , even if fertile [ 4 , 8 ] . in our patient iha levels were negative twice . \n",
    " due to the relatively non - specific clinical signs , diagnosis can only be made confidently using appropriate imaging . \n",
    " plain radiographs , ultrasonography ( us ) , or ct scans are sufficient for diagnosis , but magnetic resonance imaging ( mri ) is also very useful [ 5 , 9 ] . \n",
    " computed tomography demonstrates cyst wall calcification , infection , peritoneal seeding , bone involvement fluid density of intact cysts , and the characteristic internal structure of both uncomplicated and ruptured cysts [ 5 , 9 ] . \n",
    " the conventional treatment of hydatid cysts in all organs is surgical . in children , small hydatid cysts of the lungs \n",
    " respond favourably to medical treatment with oral administration of certain antihelminthic drugs such as albendazole in certain selected patients . \n",
    " the response to therapy differs according to age , cyst size , cyst structure ( presence of daughter cysts inside the mother cysts and thickness of the pericystic capsule allowing penetration of the drugs ) , and localization of the cyst . in children , small cysts with thin pericystic capsule localised in the brain and lungs respond favourably [ 6 , 11 ] . \n",
    " respiratory symptoms are seen predominantly in cases before two years of age . in our patient , who has vision loss , the asymptomatic duplication cyst was found incidentally . \n",
    " the lesion occupied the left hemithorax although the most common localisation reported in the literature is the lower and right oesophagus . \n",
    " the presentation depends on the site and the size of the malformations , varying from dysphagia and respiratory distress to a lump and perforation or bleeding into the intestine , but cysts are mostly diagnosed incidentally . \n",
    " if a cystic mass is suspected in the chest , the best technique for evaluation is ct . \n",
    " magnetic resonance imaging can be used to detail the intimate nature of the cyst with the spinal canal . \n",
    " duplications should have all three typical signs : first of all , they should be attached to at least one point of the alimentary tract ; second and third are that they should have a well - developed smooth muscle coat , and the epithelial lining of duplication should represent some portions of alimentary tract , respectively [ 2 , 10 , 12 ] . in summary , the cystic appearance of both can cause a misdiagnosis very easily due to the rarity of cystic oesophageal duplications as well as the higher incidence of hydatid cyst , especially in endemic areas . \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "dump(model, 'summaryModel.joblib')\n",
    "\n",
    "\n",
    "loaded_model = load('summaryModel.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oesophageal duplication ced hc presentation depends site size cyst hydatid cyst far common cystic intrathoracic lesion especially endemic area challenge differentiated hc country\n"
     ]
    }
   ],
   "source": [
    "summary=generate_summary(MEDICAL_DOCUMENT)\n",
    "print(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
